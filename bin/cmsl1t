#!/usr/bin/env python
from __future__ import print_function
import ROOT
from datetime import datetime
from cmsl1t.utils.timers import timerfunc_log_to
from cmsl1t.config import ConfigParser
from cmsl1t.utils.module import load_L1TNTupleLibrary
from cmsl1t.io.eventreader import EventReader
import click
import click_log
from importlib import import_module
import yaml
import logging
logger = logging.getLogger(__name__)
logging.getLogger("rootpy.tree.chain").setLevel(logging.ERROR)
click_log.basic_config(logger)

TODAY = datetime.now().timetuple()
ROOT.PyConfig.IgnoreCommandLineOptions = True
ROOT.gROOT.SetBatch(1)
ROOT.TH1.SetDefaultSumw2(True)
separator = '=' * 80
section = [separator, '{0}', separator]
section = '\n'.join(section)


@timerfunc_log_to(logger.info)
def process_tuples(config, nevents, analyzers, producers):
    # Open the data files
    logger.info(section.format("Loading data"))

    input_files = config.get('input', 'files')
    logger.info("Input files:")

    if len(input_files) > 10:
        file_msg = [input_files[:10], "... and",
                    len(input_files) - 10, "more files"]
        file_msg = map(str, file_msg)
        file_msg = " ".join(file_msg)
        logger.info(file_msg)
    else:
        logger.info(input_files)

    ntuple_map = config.get('input', 'ntuple_map_file')
    with open(ntuple_map) as f:
        ntuple_map = yaml.load(f)
    load_L1TNTupleLibrary()
    reader = EventReader(input_files, ntuple_map, nevents=nevents)

    results = [analyzer.prepare_for_events(reader) for analyzer in analyzers]
    check(results, analyzers, 'prepare_for_events')

    logger.info(section.format("Processing events"))
    # Fill the histograms from the tuples
    counter_rate = 1000
    if nevents <= 10000 and not nevents < 0:
        counter_rate = nevents / 10
    for entry, event in enumerate(reader):
        if entry % counter_rate == 0:
            if nevents > 0:
                logger.info("{} of {}".format(entry, nevents))
            else:
                logger.info("{} of <all>".format(entry))
        results = [p.produce(event) for p in producers]
        check(results, producers, 'produce')
        results = [analyzer.process_event(entry, event)
                   for analyzer in analyzers]
        check(results, analyzers, 'process_event')
        if all(results) is not True:
            break


@timerfunc_log_to(logger.info)
def process_histogram_files(configs, analyzer_lists, do_comparison):
    # Open the histogram files
    logger.info(section.format("Reading back histograms"))

    if do_comparison:
        inputs = [config.get('input', 'comp_file') for config in configs]
    else:
        inputs = configs[0].get('input', 'hist_files')
    logger.info("Inputs:")
    if len(inputs) > 10:
        msg = inputs[:10], "... and " + str(len(inputs) - 10) + " more"
        logger.info(msg)
    else:
        logger.info(inputs)

    # Open the histogram file
    results = {}
    if not do_comparison:
        for filename in inputs:
            for analyzer in analyzer_lists[0]:
                if analyzer not in results:
                    results[analyzer] = True
                if analyzer.might_contain_histograms(filename):
                    results[analyzer] &= bool(analyzer.reload_histograms(filename))
    else:
        for filename, analyzers in zip(inputs, analyzer_lists):
            for analyzer in analyzers:
                if analyzer not in results:
                    results[analyzer] = True
                if analyzer.might_contain_histograms(filename):
                    results[analyzer] &= \
                        bool(analyzer.reload_histograms(filename, do_comparison))

    # Check for errors
    return check(results.values(), results.keys(), 'process_histogram_files')


@timerfunc_log_to(logger.info)
def process_legacy(config, nevents, analyzers):
    logger.info(section.format("Running in legacy mode"))
    results = [analyzer.prepare_for_events(None) for analyzer in analyzers]
    check(results, analyzers, 'prepare_for_events')

    # setting entry = nevents  is ugly
    results = [analyzer.process_event(nevents, None) for analyzer in analyzers]
    check(results, analyzers, 'process_event')

    return all(results)


def run(configs, nevents, reload_histograms, do_comparison):
    results = [False]
    # Fetch the analyzers for each config
    if not do_comparison:
        unloaded_analyzer_lists = [configs[0].get('analysis', 'analyzers')]
    # Find common analyzers between the configs
    else:
        unloaded_analyzer_lists = [config.get('analysis', 'analyzers') \
                                    for config in configs]
        analyzer_names_list = [[ analyzer['name'] for analyzer in analyzers ] \
            for analyzers in unloaded_analyzer_lists]
        common_analyzer_names = \
            list(set(analyzer_names_list[0]).intersection(*analyzer_names_list[1:]))
        for config in configs:
            analyzers = config.get('analysis', 'analyzers')
            unloaded_analyzer_lists.append(
                [analyzer for analyzer in analyzers if analyzer['name'] \
                    in common_analyzer_names]
            )

    # Get output and initialize analyzers
    analyzer_lists = []
    for config, analyzers in zip(configs, unloaded_analyzer_lists):
        out_cfg = config.get('output')
        analyzers = [load_analyzer(analyzer, out_cfg) for analyzer in analyzers]
        analyzer_lists.append(analyzers)

    if not reload_histograms:
        # Use producers from first config, not needed for comparisons
        producers = configs[0].get('analysis', 'producers')
        producers = [load_producer(producer, configs[0].get('output')) \
                        for producer in producers]
        _check_producer_outputs(producers)

        analysis_mode = configs[0].try_get('analysis', 'mode', default='new')
        if analysis_mode == 'legacy':
            process_legacy(configs[0], nevents, analyzer_lists[0])
        else:
            process_tuples(configs[0], nevents, analyzer_lists[0], producers)
    else:
        process_histogram_files(configs, analyzer_lists, do_comparison)

    # Write out the histograms [item for sublist in l for item in sublist]
    for analyzer in [analyzer for analyzers in analyzer_lists \
                        for analyzer in analyzers]:
        analyzer.write_histograms()

    # Turn the histograms to plots
    logger.info(section.format("Making plots"))
    if not do_comparison:
        results = [analyzer.make_plots() for analyzer in analyzer_lists[0]]
    else:
        # Need to transpose list of analyzers for each config
        # to get the other comparison analyzers...
        results = [analyzer.make_plots(other_analyzers[1:]) \
            for analyzer, other_analyzers in \
                zip(analyzer_lists[0], [list(i) for i in zip(*analyzer_lists)])]
    check(results, analyzer_lists[0], 'make_plots')

    # Finalize
    print(section.format("Finalizing things"))
    results = [analyzer.finalize() for analyzers in analyzer_lists \
                for analyzer in analyzers]
    check(results, [analyzer for analyzers in analyzer_lists \
                for analyzer in analyzers], 'finalize')

    return all(results)


def _check_producer_outputs(producers):
    outputs = []
    for p in producers:
        for o in p._outputs:
            if o in outputs:
                msg = 'Producer output {} already defined by other producers'.format(
                    o)
                logger.error(msg)
                raise AttributeError(msg)
        outputs += p._outputs


def check(results, analyzers, method):
    msg = 'Problem during {method}() with analyzer "{analyzer}"'
    is_ok = all(results)
    if not is_ok:
        for i, r in enumerate(results):
            if r is not True:
                logger.error(msg.format(method=method, analyzer=analyzers[i]))
    return is_ok


@click.command()
@click.option('-c', '--config_files', help='YAML style config file',
                type=click.File(), required=True, multiple=True)
@click.option('-n', '--nevents', default=-1, help='Number of events to process.')
@click.option('-r', '--reload-histograms', is_flag=True,
              help="Reload histograms from a file and skip the input tuples")
@click.option('--hist-files', default=None,
              help="Provide a list of files to reload histograms from")
@click.option('-cf', '--comp_files', default=None, multiple=True,
              help="Reload histograms from multiple files for comparison,\
                    e.g. -cf <title1>:<file1> -cf <title2>:<file2> ...")
@click_log.simple_verbosity_option(logger)
def analyze(config_files, nevents, reload_histograms, hist_files, comp_files):
    logger.info(section.format("Starting CMS L1T Analysis"))
    if comp_files and (len(comp_files) != len(config_files)):
        msg = "Must provide equal number of config files & root files\
                for comparison. Exiting..."
        raise IOError(msg)
    if comp_files and hist_files:
        msg = "Please choose either comp-files or hist-files. Exiting..."
        raise IOError(msg)
    if not comp_files and len(config_files) > 1:
        msg = "Can only take one config file unless running comparisons. Exiting..."
        raise IOError(msg)
    configs = []
    do_comparison = False
    if comp_files:
        do_comparison = True
        reload_histograms = True
        for config_file, comp_file in zip(config_files, comp_files):
            config = ConfigParser()
            config.read(config_file, reload_histograms, hist_files, comp_file)
            configs.append(config)
    else:
        config = ConfigParser()
        config.read(config_files[0], reload_histograms, hist_files)
        configs.append(config)

    isok = run(configs, nevents, reload_histograms, do_comparison)

    print('\n' + separator + '\n')
    if isok is not True:
        logger.info("There were errors during running:")
        logger.info(isok)
        logger.info('\n' + separator + '\n')


def load_analyzer(analyzer, output_cfg):
    name = analyzer['name']
    module = analyzer.pop('module')
    logger.info("Try loading analyzer: {0} ({1})".format(name, module))
    module = import_module(module)
    logger.info("Successfully loaded analyzer: {0} ({1})".format(name, module))
    cfg = dict(output_folder=output_cfg['folder'],
               plots_folder=output_cfg['plots_folder'],
               file_format=output_cfg.get('plot_format', 'pdf'),
               )
    cfg.update(analyzer)
    return module.Analyzer(**cfg)


def load_producer(producer, output_cfg):
    name = producer.pop('name')
    module = producer.pop('module')
    logger.info("Try loading producer: {0} ({1})".format(name, module))
    module = import_module(module)
    logger.info("Successfully loaded producer: {0} ({1})".format(name, module))
    cfg = dict(output_folder=output_cfg['folder'],
               plots_folder=output_cfg['plots_folder'],
               file_format=output_cfg.get('plot_format', 'pdf'),
               )
    cfg.update(producer)
    return module.Producer(**cfg)


if __name__ == '__main__':
    analyze()
